# ğŸ¶ Scrape The Verse

*He wrote â€œTangled Up in Blue,â€ she wrote â€œThe Story of Usâ€â€”we wrote the code to ask if Swift could follow Dylan to Stockholm.*

> ğŸ“š This project is a full-blown, ETL-powered attempt to answer one brilliant, nerdy, and slightly unhinged question:  
> **Can Taylor Swift win the Nobel Prize in Literature?**  
> (Spoiler: if Bob Dylan did, why not her?)

> *â€œThereâ€™s no success like failure, and failureâ€™s no success at all.â€* â€” Bob Dylan  
> *â€œI want to be defined by the things that I love.â€* â€” Taylor Swift

---

## ğŸš€ What is this?

**Scrape The Verse** is a modular ETL + NLP pipeline built in Python to scrape and analyze:

- ğŸ§ Spotify metadata (artists, albums, songs)
- ğŸ“ Genius lyrics (by album)
- ğŸ§  Wikidata metadata (biographical and artistic traits)

With one literary mission:  
**Build a clean, analyzable dataset to explore songwriting quality through the lens of literary merit.**

---

## ğŸ§  Project Status

**Stable and modular** â€” the project is fully functional and structured as a clear ETL pipeline with reusable components and database integration.

### âœ… Core Features

- Modular scrapers for Spotify, Genius, and Wikidata
- Lyrics + metadata transformation and merging
- Track-level NLP analysis:
  - Flesch readability
  - Sentiment (VADER)
  - Lexical density
  - Word/line/character counts
- Word frequency tables for tracks and albums
- PostgreSQL loader with relational schema + data integrity
- Robust dependency validation (`nltk`, `spaCy`, etc.)
- Batch logging of missing or matched lyrics
- Fully interactive CLI for all pipeline stages
- Clean, testable, documented and type-annotated Python code (SOLID-ready)

---

## ğŸ“ Project Structure

```text
src/
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ analyze_lyrics.py
â”œâ”€â”€ extraction/
â”‚   â”œâ”€â”€ genius_extraction.py
â”‚   â”œâ”€â”€ spotify_extraction.py
â”‚   â””â”€â”€ wikidata_extraction.py
â”œâ”€â”€ transformation/
â”‚   â”œâ”€â”€ genius_transformation.py
â”‚   â”œâ”€â”€ spotify_transformation.py
â”‚   â””â”€â”€ wikidata_transformation.py
â”œâ”€â”€ processing/
â”‚   â””â”€â”€ process.py
â”œâ”€â”€ load/
â”‚   â”œâ”€â”€ load.py

raw/
â”œâ”€â”€ GENIUS/
â”œâ”€â”€ SPOTIFY/
â””â”€â”€ WIKIDATA/

transformations/
â”œâ”€â”€ GENIUS/
â””â”€â”€ SPOTIFY/

processed/
â””â”€â”€ <artist>/
    â””â”€â”€ <album>_final.csv

logs/
db/
â””â”€â”€ create_schema.sql
```

---

## âš™ï¸ Setup

### 1. Clone the repo

```bash
git clone https://github.com/<your-username>/Scrape-The-Verse.git
cd Scrape-The-Verse
```

### 2. Create your `.env` file

```dotenv
SPOTIPY_CLIENT_ID=your_spotify_id
SPOTIPY_CLIENT_SECRET=your_spotify_secret
SPOTIPY_REDIRECT_URI=http://localhost:8080
GENIUS_CLIENT_ACCESS_TOKEN=your_genius_token
POSTGRES_DB=your_database
POSTGRES_USER=your_user
POSTGRES_PASSWORD=your_password
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
```

### 3. Create and activate the Conda environment

```bash
conda create -n scraptheverse python=3.10
conda activate scraptheverse
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

---

## ğŸ§ª Initialize the Database

Before loading data, create the PostgreSQL schema:

```bash
psql -U <your_user> -d <your_database> -f db/create_schema.sql
```

Or run it directly in DBeaver.

---

## â–¶ï¸ Run the Pipeline

Run each step of the pipeline via CLI:

```bash
# Step 1: Scrape data
python src/extraction/spotify_extraction.py
python src/extraction/genius_extraction.py
python src/extraction/wikidata_extraction.py

# Step 2: Clean & transform
python src/transformation/spotify_transformation.py
python src/transformation/genius_transformation.py
python src/transformation/wikidata_transformation.py

# Step 3: Merge lyrics with tracks
python src/processing/process.py

# Step 4: Load to PostgreSQL
python src/load/load.py

# Step 5: Analyze lyrics
python src/analysis/analyze_lyrics.py
```

You can run every step at once, too.

```bash
python main.py
```

---

## ğŸ“Š Database Schema Overview

Includes:

- `artists`: identity & biography  
- `albums`: linked to artist  
- `tracks`: song-level data  
- `lyrics`: raw text + readability, sentiment, lexical stats  
- `word_frequencies_track`: for song-level word clouds  
- `word_frequencies_album`: for album-level word clouds

Defined in [`db/create_schema.sql`](db/create_schema.sql)

---

## ğŸ’¡ Example Use Cases

- Compare **lexical density** of Bob Dylan vs Taylor Swift  
- Visualize **frequent motifs** (love, time, silence...) by album  
- Track evolution of **sentiment** or **explicitness** across eras  
- Build dashboards to answer: *"Is this Nobel-worthy poetry?"*

---

## ğŸ¤ Contributing

Pull requests welcome â€” especially from Swifties who know SQL.  
Justâ€¦ please donâ€™t fight about *Folklore* vs *1989* in the issues.

---

## âœ¨ Credits

Built by a language nerd with an overactive playlist.  
Inspired by literature, lyrics, and one very specific Nobel Prize.

> â€œYouâ€™re on your own, kidâ€”but the script runs fine.â€  
> â€” T. Swift, sort of.
