# ğŸ¶ Scrape The Verse

![Python](https://img.shields.io/badge/python-3.10-blue)
![Database](https://img.shields.io/badge/database-PostgreSQL-blue)
![Status](https://img.shields.io/badge/status-stable-brightgreen)
![ETL Pipeline](https://img.shields.io/badge/etl-complete-brightgreen)
![NLP Ready](https://img.shields.io/badge/nlp-integrated-orange)
![License](https://img.shields.io/badge/license-MIT-green)
![Made with â¤ï¸](https://img.shields.io/badge/made%20with-%E2%9D%A4-red)
![Built by a Swiftie](https://img.shields.io/badge/built%20by-Swifties-ec87c0?style=flat-square&logo=taylor-swift)
![Inspired by Dylan](https://img.shields.io/badge/inspired%20by-Dylan-6f4e37?style=flat-square&logo=lyrics)


*He wrote â€œTangled Up in Blue,â€ she wrote â€œThe Story of Usâ€â€”we wrote the code to ask if Swift could follow Dylan to Stockholm.*

> ğŸ“š This project is a full-blown, ETL-powered attempt to answer one brilliant, nerdy, and slightly unhinged question:  
> **Can Taylor Swift win the Nobel Prize in Literature?**  
> (Spoiler: if Bob Dylan did, why not her?)

> *â€œThereâ€™s no success like failure, and failureâ€™s no success at all.â€* â€” Bob Dylan  
> *â€œI want to be defined by the things that I love.â€* â€” Taylor Swift

---

## ğŸš€ What is this?
**â€œItâ€™s me, hi â€” Iâ€™m the pipeline, itâ€™s me.â€**

**Scrape The Verse** is a modular ETL + NLP pipeline built in Python to scrape and analyze:

- ğŸ§ Spotify metadata (artists, albums, songs)
- ğŸ“ Genius lyrics (by album)
- ğŸ§  Wikidata metadata (biographical and artistic traits)

With one literary mission:  
**Build a clean, analyzable dataset to explore songwriting quality through the lens of literary merit.**

---

## ğŸ§  Project Status
**â€œThe times they are a-changinâ€™ â€” but this repoâ€™s ready.â€**

**Stable and modular** â€” the project is fully functional and structured as a clear ETL pipeline with reusable components and database integration.

### âœ… Core Features

- Modular scrapers for Spotify, Genius, and Wikidata
- Lyrics + metadata transformation and merging
- Track-level NLP analysis:
  - Flesch readability
  - Sentiment (VADER)
  - Lexical density
  - Word/line/character counts
- Word frequency tables for tracks and albums
- PostgreSQL loader with relational schema + data integrity
- Robust dependency validation (`nltk`, `spaCy`, etc.)
- Batch logging of missing or matched lyrics
- Fully interactive CLI for all pipeline stages
- Clean, testable, documented and type-annotated Python code (SOLID-ready)

---

## ğŸ“ Project Structure  
**â€œOrganized like a vault track. Documented like â€˜Desolation Row.â€™â€**

```text
src/
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ analyze_lyrics.py
â”œâ”€â”€ extraction/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ genius_extraction.py
â”‚   â”œâ”€â”€ spotify_extraction.py
â”‚   â””â”€â”€ wikidata_extraction.py
â”œâ”€â”€ transformation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ genius_transformation.py
â”‚   â”œâ”€â”€ spotify_transformation.py
â”‚   â””â”€â”€ wikidata_transformation.py
â”œâ”€â”€ process/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ process.py
â”œâ”€â”€ load/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ load.py

raw/
â”œâ”€â”€ GENIUS/
â”œâ”€â”€ SPOTIFY/
â””â”€â”€ WIKIDATA/

transformations/
â”œâ”€â”€ GENIUS/
â””â”€â”€ SPOTIFY/

processed/
â””â”€â”€ <artist>/
    â””â”€â”€ <album>_final.csv

docs/
â”œâ”€â”€ gifs/
â”œâ”€â”€ index.md
â”œâ”€â”€ installation.md
â”œâ”€â”€ overview.md
â””â”€â”€ usage.md

db/
â””â”€â”€ create_schema.sql

logs/
```

---

## âš™ï¸ Setup
**â€œFirst you get the access token, then you get the data, then you change the world.â€**

From cloning to conda to credentials, itâ€™s all here â€” just like a deluxe edition rollout.

### 1. Clone the repo

```bash
git clone https://github.com/<your-username>/Scrape-The-Verse.git
cd Scrape-The-Verse
```

### 2. Create your `.env` file

```dotenv
SPOTIPY_CLIENT_ID=your_spotify_id
SPOTIPY_CLIENT_SECRET=your_spotify_secret
SPOTIPY_REDIRECT_URI=http://localhost:8080
GENIUS_CLIENT_ACCESS_TOKEN=your_genius_token
POSTGRES_DB=your_database
POSTGRES_USER=your_user
POSTGRES_PASSWORD=your_password
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
```

### 3. Create and activate the Conda environment

```bash
conda create -n scraptheverse python=3.10
conda activate scraptheverse
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

---

## ğŸ§ª Initialize the Database
**â€œSome PostgreSQL tables, just to keep you company.â€**  
(*Probably* what Taylor says to her ERD diagrams.)

Before loading data, create the PostgreSQL schema:

```bash
psql -U <your_user> -d <your_database> -f db/create_schema.sql
```

Or run it directly in DBeaver.

---

## â–¶ï¸ Run the Pipeline
**â€œFrom Red to Reputation, one script at a time.â€**

Whether you're running it track by track or all at once, this pipeline flows smoother than *Blonde on Blonde*.

```bash
# Step 1: Scrape data
python src/extraction/spotify_extraction.py
python src/extraction/genius_extraction.py
python src/extraction/wikidata_extraction.py

# Step 2: Clean & transform
python src/transformation/spotify_transformation.py
python src/transformation/genius_transformation.py
python src/transformation/wikidata_transformation.py

# Step 3: Merge lyrics with tracks
python src/process/process.py

# Step 4: Load to PostgreSQL
python src/load/load.py

# Step 5: Analyze lyrics
python src/analysis/analyze_lyrics.py
```

You can run every step at once, too.

```bash
python main.py
```

---

---

## ğŸ¥ Pipeline Demo
**â€œWe bring receipts â€” and by that, we mean animated .gifs.â€**

A visual tour from scraping to NLP, because if itâ€™s not in a GIF, did it even happen?

### ğŸ” Extraction
![Extraction](docs/gifs/extraction.gif)

### ğŸ§¼ Transformation
![Transformation](docs/gifs/transformation.gif)

### ğŸ§© Merging Lyrics with Metadata
![Merging](docs/gifs/merge.gif)

### ğŸ’¾ Loading to PostgreSQL
![Loading](docs/gifs/loading.gif)

### ğŸ“ˆ NLP Analysis
![Analysis](docs/gifs/analysis.gif)


---

## ğŸ“Š Database Schema Overview
**â€œStructured like a bridge. Normalized like a Dylan verse.â€**

Includes everything from `lyrics` to `word_frequencies_album`. No easter eggs, just solid SQL.

- `artists`: identity & biography  
- `albums`: linked to artist  
- `tracks`: song-level data  
- `lyrics`: raw text + readability, sentiment, lexical stats  
- `word_frequencies_track`: for song-level word clouds  
- `word_frequencies_album`: for album-level word clouds

Defined in [`db/create_schema.sql`](db/create_schema.sql)

---

## ğŸ’¡ Example Use Cases
**â€œUse cases that go deeper than Track 5.â€**

- Compare **lexical density** of Bob Dylan vs Taylor Swift  
- Visualize **frequent motifs** (love, time, silence...) by album  
- Track evolution of **sentiment** or **explicitness** across eras  
- Build dashboards to answer: *"Is this Nobel-worthy poetry?"*

---

## ğŸ“Š Power BI Dashboard Demos
**â€œIf a chart falls in the forest, but itâ€™s not in Power BI, did it really insight?â€**

A first look at the visual storytelling behind the metrics. Think *Miss Americana* meets *Donâ€™t Look Back*.

### ğŸ§¾ Summary Cards View
![Summary Cards](docs/gifs/dashboard_overview.gif)

### âœï¸ Literary Quality Breakdown
![Literary Quality](docs/gifs/literary_quality_page.gif)

### â¤ï¸ Emotional Depth & Sentiment
![Emotional Depth](docs/gifs/emotional_depth_page.gif)

---

## ğŸ¤ Contributing  
**â€œBring your pull requests â€” and your cardigan.â€**

Pull requests are always welcome â€” especially if you can write a left join with the same finesse as a bridge in *All Too Well (10 Minute Version)*.  
Just one rule: no *Folklore* vs *1989* wars in the issues. We honor the whole catalog here.

---

## âœ¨ Credits
**â€œBuilt by a Swiftie. Haunted by a Dylan lyric.â€**

Created by Manuel Cruz RodrÃ­guez â€” a language lover with too many browser tabs and a playlist that wonâ€™t quit.  
Born from books, lyricsâ€¦ and one Nobel Prize nobody saw coming.

> â€œYouâ€™re on your own, kid â€” but this script doesnâ€™t need backup.â€  
> â€” T. Swift, if she used Git.

